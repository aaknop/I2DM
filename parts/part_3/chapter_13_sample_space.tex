\chapter{Sample Spaces and Events}
In the previous chapter we discussed games that do not involve move by chance.
A theory that studies experiments, processes and interactions that are subject
to chance is called \emph{probability theory}; we are going to study this theory
in this part.

The most important assumption of probability theory is that nonetheless the
outcome of an experiment is not known in advance --- the set of all possible
outcomes is known. This set is called the \emph{sample space} or the
\emph{probability space}.

For example, if our experiment consists of tossing a coin, then the sample space
consists of two outcomes $\set{H, T}$, where $H$ stands for heads and $T$ stands
for tails.
\begin{exercise}
  Write the sample space for the experiment consisting of tossing two coins.
\end{exercise}
Each element of the sample space is called an \emph{outcome} or an
\emph{elementary event}. Typically, we are interested in observing several
outcomes; e.g., in the experiment consisting of tossing five coins, the set
$\set{HTTTT, THTTT, TTHTT, TTTHT, TTTTH}$ describe all possible outcomes when
exactly one coin shows heads. We say that a set of outcomes is an \emph{event}.

Another assumption of probability theory is that every outcome $\omega$ of a
sample space $\Omega$ is assigned some probability $\Pr(\omega)$; intuitively,
$\Pr(\omega)$ is the likelihood that the outcome $\omega$ occur in the
experiment. It is convenient to normalize probabilities, so we require that 
$0 \le \Pr(\omega) \le 1$ for all $\omega \in \Omega$ and 
$\sum_{\omega \in \Omega} \Pr(\omega) = 1$. The function $\Pr$ is called
a \emph{probability distribution} on $\Omega$.

The pair of a sample space and a probability distribution on the space is called
a \emph{finite discrete probability space}.


We can extend the notion of probability from elementary events to all events as
follows. Let $E \subseteq \Omega$ be an event in the finite discrete probability
space $(\Omega, \Pr)$. Then $\Pr(E)$ denote the sum of all $\Pr(\omega)$ for
$\omega \in \Omega$. In the sequel, we use $\sum_{\omega \in E} \Pr(\omega)$ to
describe similar sums (see \Cref{section:generalized-sum} for a formal
definition).
\nomenclature[C]{$\sum_{i \in S ~:~ P(i)} \alpha_i$}{denotes $\alpha_{i_1} +
\dots + \alpha_{i_k}$, where $\set[P(i)]{i \in S} = \set{i_1, \dots, i_k}$}


\begin{exercise}
  In many cases we consider \emph{uniform distribution} on a set $\Omega$, the
  distribution $\Pr$ such that all the outcomes are equally likely.
  Let $\Omega = \set{HH, HT, TH, TT}$ and $\Pr$ be the uniform distribution on
  $\Omega$. Find the probability of the event $\set{HT, TH, TT}$, and give an
  informal interpretation of the answer.
\end{exercise}

Events are subsets of the sample space; hence, they can be combined using the
standard set operations. So it is natural to ask whether the probabilities
$\Pr(A \cup B)$ and $\Pr(A \cap B)$ can be expressed in terms of $\Pr(A)$ and
$\Pr(B)$.

\begin{theorem}[The Additive Principle]
  Let $(\Omega, \Pr)$ be a finite discrete probability space, and let $A, B
  \subseteq \Omega$ be two disjoint events. Then 
  $\Pr(A \cup B) = \Pr(A) + \Pr(B)$.
\end{theorem}
\begin{proof}[Proof Sketch, see \Cref{theorem:additive-principle}]
  Let $A = \set{\omega_{1, 1}, \dots, \omega_{1, k}}$ and 
  let $B = \set{\omega_{2, 1}, \dots, \omega_{2, \ell}}$. 
  Then $A \cup B = \set{\omega_{1, 1}, \dots, \omega_{1, k}, 
    \omega_{2, 1}, \dots, \omega_{2, \ell}}$.
  Therefore $\Pr(A \cup B) = 
    \Pr(\omega_{1, 1}) + \dots + \Pr(\omega_{2, k}) +
    \Pr(\omega_{2, 1}) + \dots + \Pr(\omega_{2, \ell}) = \Pr(A) + \Pr(B)$.
\end{proof}

\begin{exercise}
  Let $(\Omega, \Pr)$ be a finite discrete probability space, and let $A
  \subseteq A$ be an event. Show that $\Pr(A) = 1 - \Pr(A)$.
\end{exercise}

This result can be easily extended to the cases when $A$ and $B$ are not
disjoint.
\begin{corollary}[The Inclusion-exclusion Principle]
\label{corollary:inclusion-exclusion-probability}
  Let $(\Omega, \Pr)$ be a finite discrete probability space, and let $A, B
  \subseteq \Omega$ be two events. Then 
  $\Pr(A \cup B) = \Pr(A) + \Pr(B) - \Pr(A \cap B)$.
\end{corollary}

Unfortunately, $\Pr(A \cap B)$ cannot be expressed via $\Pr(A)$ and $\Pr(B)$.
However, in many cases $\Pr(A \cap B) = \Pr(A) \Pr(B)$; if this equality holds,
we say that $A$ and $B$ are \emph{independent}.

For example, let us consider an experiment where we toss two fair coins; i.e.,
let us consider $\Omega = \set{HH, HT, TH, TT}$ and let $\Pr$ be a uniform
distribution on $\Omega$. It is easy to see that $\Pr(\set{HH, HT}) = 1 / 2$,
$\Pr(\set{HH, TH}) = 1 / 2$, and $\Pr(\set{HH, HT} \cap \set{HH, TH}) =
\Pr(\set{HH}) =  1 / 4$. Hence, these two events are independent.

To analyze experiments consisting of tossing several coins, we need to be able
to study products of finite discrete probability spaces.
\begin{theorem}[The Multiplicative Principle]
\label{theorem:multiplicative-principle-probability}
  Let $\Omega = \Omega_1 \times \Omega_2$ and let $(\Omega_1, \Pr_1)$ and
  $(\Omega_2, \Pr_2)$ be finite discrete probability spaces. Then $\Pr : \Omega
  \to \R$ such that $\Pr(\omega_1, \omega_2) = \Pr_1(\omega_1) \cdot
  \Pr_2(\omega_2)$ is a probability distribution on $\Omega$.
  Moreover, $\Pr(E_1 \times E_2) = \Pr_1(E_1) \cdot \Pr_2(E_2)$ for all 
  $E_1 \subseteq \Omega_1$ and $E_2 \subseteq \Omega_2$.
\end{theorem}

Using this principle we can show that in the experiment consisting of tossing
five coins, the event where the first flip is $H$ and the event where the second
flip is $H$ are independent. Indeed, let $\Omega = \set{H, T}^5$; 
$\Pr$ be the uniform distribution on $\Omega$; and 
$E_1 = \set[t_1 = H]{t \in \set{H, T}^5}$ and
$E_2 = \set[t_2 = H]{t \in \set{H, T}^5}$. By
\Cref{theorem:multiplicative-principle-probability},
$\Pr(E_1) = \Pr(E_2) = 1 / 2$. Moreover, 
$E_1 \cap E_2 = \set[t_1 = H \text{ and } t_2 = H]{t \in \set{H, T}^5}$;
therefore, $\Pr(E_1 \cap E_2) = \frac{1}{4}$.

\begin{chapterendexercises}
  \exercise Prove \Cref{corollary:inclusion-exclusion-probability}.
  \exercise Let $\Omega = \set{HH, HT, TH, TT}$ and let $\Pr$ be a uniform
    distribution on $\Omega$. Show that $\set{HH}$ and $\set{TT}$ are not
    independent.
  \exercise Alice is rolling a dice $n$ times, compute the probability
    that Alice sees $6$, $6$, and $6$ in three consecutive rolls.
  \exercise Alice is rolling a dice $n$ times, compute the probability
    that Alice sees $4$, $5$, and $6$ in three consecutive rolls.
\end{chapterendexercises}
