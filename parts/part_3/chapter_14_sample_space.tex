\chapter{Sample Spaces and Events}
In the previous chapter we discussed games that do not involve move by chance.
A theory that studies experiments, processes and interactions that are subject
to chance is called \emph{probability theory}; we are going to study this theory
in this part.

The most important assumption of probability theory is that nonetheless the
outcome of an experiment is not known in advance --- the set of all possible
outcomes is known. This set is called the \emph{sample space} or the
\emph{probability space}.

For example, if our experiment consists of tossing a coin, then the sample space
consists of two outcomes $\set{H, T}$, where $H$ stands for heads and $T$ stands
for tails.
\begin{exercise}
  Write the sample space for the experiment consisting of tossing two coins.
\end{exercise}
Each element of the sample space is called an \emph{outcome} or an
\emph{elementary event}. Typically, we are interested in observing several
outcomes; e.g., in the experiment consisting of tossing five coins, the set
$\set{HTTTT, THTTT, TTHTT, TTTHT, TTTTH}$ describe all possible outcomes when
exactly one coin shows heads. We say that a set of outcomes is an \emph{event}.

Another assumption of probability theory is that every outcome $\omega$ of a
sample space $\Omega$ is assigned some probability $\Distribution{D}(\omega)$;
intuitively, $\Distribution{D}(\omega)$ is the likelihood that the outcome
$\omega$ occurs in the experiment. It is convenient to normalize probabilities,
so we require that $0 \le \Distribution{D}(\omega) \le 1$ for all $\omega \in
\Omega$ and the sum of $\Distribution{D}(\omega)$ for $\omega \in \Omega$ is
equal to $1$. 
(In the sequel, we use $\sum_{x \in X} f(x)$ to describe the sum of $f(x)$ for
$x \in X$; see \Cref{section:generalized-sum} for the formal definition.)
\nomenclature[C]{$\sum_{i \in S ~:~ P(i)} \alpha_i$}{denotes $\alpha_{i_1} +
\dots + \alpha_{i_k}$, where $\set[P(i)]{i \in S} = \set{i_1, \dots, i_k}$}
The function $\Distribution{D}$ is called a \emph{probability distribution} on
$\Omega$.

The pair of a sample space and a probability distribution on the space is called
a \emph{finite discrete probability space}.

We can extend the notion of probability from elementary events to all events as
follows. Let $E \subseteq \Omega$ be an event in the finite discrete probability
space $(\Omega, \Distribution{D})$. Then $\Pr_{\Distribution{D}}(E)$ denotes
$\sum_{\omega \in E} \Distribution{D}(\omega)$. 

\begin{exercise}
  In many cases we consider \emph{uniform distribution} on a set $\Omega$, the
  distribution $\Uniform{\Omega}$ such that all the outcomes are equally
  likely.
  Let $\Omega = \set{HH, HT, TH, TT}$ and $\Uniform{\Omega}$ be the
  uniform distribution on $\Omega$. Find the probability of the event 
  $\set{HT, TH, TT}$, and give an informal interpretation of the answer.
\end{exercise}

\section{Basic Principles}

Events are subsets of the sample space; hence, they can be combined using the
standard set operations. So it is natural to ask whether the probabilities
$\Pr_{\Distribution{D}}(A \cup B)$ and $\Pr_{\Distribution{D}}(A \cap B)$ can be
expressed in terms of $\Pr_{\Distribution{D}}(A)$ and $\Pr_{\Distribution{D}}(B)$.

\begin{theorem}[The Additive Principle]
  Let $(\Omega, \Distribution{D})$ be a finite discrete probability space, and let $A, B
  \subseteq \Omega$ be two disjoint events. Then 
  $\Pr_{\Distribution{D}}(A \cup B) = \Pr_{\Distribution{D}}(A) +
  \Pr_{\Distribution{D}}(B)$.
\end{theorem}
\begin{proof}[Proof Sketch, see \Cref{theorem:additive-principle}]
  Let $A = \set{\omega_{1, 1}, \dots, \omega_{1, k}}$ and 
  let $B = \set{\omega_{2, 1}, \dots, \omega_{2, \ell}}$. 
  Then $A \cup B = \set{\omega_{1, 1}, \dots, \omega_{1, k}, 
    \omega_{2, 1}, \dots, \omega_{2, \ell}}$.
  Therefore $\Pr_{\Distribution{D}}(A \cup B) = 
    \Pr_{\Distribution{D}}(\omega_{1, 1}) + \dots +
    \Pr_{\Distribution{D}}(\omega_{2, k}) +
    \Pr_{\Distribution{D}}(\omega_{2, 1}) + \dots +
    \Pr_{\Distribution{D}}(\omega_{2, \ell}) = 
    \Pr_{\Distribution{D}}(A) +
    \Pr_{\Distribution{D}}(B)$.
\end{proof}

\begin{exercise}
  Let $(\Omega, \Distribution{D})$ be a finite discrete probability space, and let $A
  \subseteq \Omega$ be an event. Show that 
  $\Pr_{\Distribution{D}}(\Omega \setminus A) = 1 - \Pr_{\Distribution{D}}(A)$.
\end{exercise}

This result can be easily extended to the cases when $A$ and $B$ are not
disjoint.
\begin{corollary}[The Inclusion-exclusion Principle]
\label{corollary:inclusion-exclusion-probability}
  Let $(\Omega, \Pr)$ be a finite discrete probability space, and let $A, B
  \subseteq \Omega$ be two events. Then 
  $\Pr_{\Distribution{D}}(A \cup B) = \Pr_{\Distribution{D}}(A) +
   \Pr_{\Distribution{D}}(B) -
   \Pr_{\Distribution{D}}(A \cap B)$.
\end{corollary}

Unfortunately, $\Pr_{\Distribution{D}}(A \cap B)$ cannot be expressed via
$\Pr_{\Distribution{D}}(A)$ and $\Pr_{\Distribution{D}}(B)$.
However, in many cases $\Pr_{\Distribution{D}}(A \cap B) =
\Pr_{\Distribution{D}}(A) \Pr_{\Distribution{D}}(B)$; if this equality holds,
we say that $A$ and $B$ are \emph{independent}.

For example, let us consider an experiment where we toss two fair coins; i.e.,
let us consider $\Omega = \set{HH, HT, TH, TT}$ and let
$\Uniform{\Omega}$ be the uniform distribution on $\Omega$. It is easy to
see that $\Pr_{\Uniform{\Omega}}(\set{HH, HT}) = 1 / 2$,
$\Pr_{\Uniform{\Omega}}(\set{HH, TH}) = 1 / 2$, and
$\Pr_{\Uniform{\Omega}}(\set{HH, HT} \cap \set{HH, TH}) =
\Pr_{\Uniform{\Omega}}(\set{HH}) =  1 / 4$. Hence, these two events are
independent.

To analyze experiments consisting of tossing several coins, we need to be able
to study products of finite discrete probability spaces.
\begin{theorem}[The Multiplicative Principle]
\label{theorem:multiplicative-principle-probability}
  Let $\Omega = \Omega_1 \times \Omega_2$ and 
  let $(\Omega_1, \Distribution{D}_1)$ and
  $(\Omega_2, \Distribution{D}_2)$ be finite discrete probability spaces. Then 
  $\Distribution{D} : \Omega \to \R$ such that 
  $\Distribution{D}(\omega_1, \omega_2) = 
  \Pr_{\Distribution{D}_1}(\omega_1) \cdot \Pr_{\Distribution{D}_2}(\omega_2)$
  is a probability distribution on $\Omega$.
  Moreover, $\Pr_{\Distribution{D}}(E_1 \times E_2) = 
  \Pr_{\Distribution{D}_1}(E_1) \cdot \Pr_{\Distribution{D}_2}(E_2)$ for all 
  $E_1 \subseteq \Omega_1$ and $E_2 \subseteq \Omega_2$.
\end{theorem}

Using this principle we can show that in the experiment consisting of tossing
five coins, the event where the first flip is $H$ and the event where the second
flip is $H$ are independent. Indeed, let $\Omega = \set{H, T}^5$; 
$\Pr$ be the uniform distribution on $\Omega$; and 
$E_1 = \set[t_1 = H]{t \in \set{H, T}^5}$ and
$E_2 = \set[t_2 = H]{t \in \set{H, T}^5}$. By
\Cref{theorem:multiplicative-principle-probability},
$\Pr(E_1) = \Pr(E_2) = 1 / 2$. Moreover, 
$E_1 \cap E_2 = \set[t_1 = H \text{ and } t_2 = H]{t \in \set{H, T}^5}$;
therefore, $\Pr_{\Distribution{D}}(E_1 \cap E_2) = \frac{1}{4}$.

\section{Random Variables}
Sometimes we are more interested in some function of the result of the
experiment rather than the result itself. For example, Sasha may play Dungeons
and Dragons and be interested in his chances to roll $7$ on two dice together.
Let us formalize the question. Let $\Omega = \range{6}^2$ and $\Pr$ be a the
uniform distribution on $\Omega$. Sasha is interested in the probability of the
event $\set[x + y = 7]{(x, y) \in \range{6}^2}$.

More generally, let $(\Omega, \Distribution{D})$ be a finite discrete
probability space. Then a function $\chi : \Omega \to \R$ is called a
\emph{random variable} and
$\Pr_{\Distribution{D}}(\chi = a)$ denotes 
$\Pr_{\Distribution{D}}(\set[\chi(\omega) = a]{\omega \in \Omega})$. 

In the example about Dungeons and Dragons, $\chi(x, y) = x + y$ and 
we are interested in $\Pr_{\Distribution{D}}(\chi = 7) = 
\Pr_{\Distribution{D}}(\set{(1, 6), (2, 5), \dots, (6, 1)} = 1 / 6$.
\begin{exercise}
  Let $\Omega = \range{6}^2$ and $\Uniform{\Omega}$ be the uniform distribution
  on $\Omega$. Let $\chi : \Omega \to \R$ be the random variable such that 
  $\chi(x, y) = x + y$. Find $\Pr_{\Uniform{\Omega}}(\chi = 1)$, \dots,
  $\Pr_{\Uniform{\Omega}}(\chi = 12)$.
\end{exercise}

We are going to adopt some simple additional notation, if 
$\chi_1, \chi_2 : \Omega \to \R$ are random variables then 
$(\chi_1 + \chi_2), (\chi_1 \cdot \chi_2) : \Omega \to \R$ are the random
variables such that $(\chi_1 + \chi_2)(\omega) = \chi_1(\omega) +
\chi_2(\omega)$ and $(\chi_1 \cdot \chi_2)(\omega) = \chi_1(\omega) \cdot
\chi_2(\omega)$.

\begin{chapterendexercises}
  \exercise Prove \Cref{corollary:inclusion-exclusion-probability}.
  \exercise Let $\Omega = \set{HH, HT, TH, TT}$ and let $\Uniform{\Omega}$ be
    the uniform distribution on $\Omega$. Show that $\set{HH}$ and $\set{TT}$
    are not independent.
  \exercise Alice is rolling a dice $n$ times, compute the probability
    that Alice sees $6$, $6$, and $6$ in three consecutive rolls.
  \exercise Alice is rolling a dice $n$ times, compute the probability
    that Alice sees $4$, $5$, and $6$ in three consecutive rolls.
\end{chapterendexercises}
